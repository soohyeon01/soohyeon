{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Python & numpy review\n",
    "\n",
    "- 유용한 강좌\n",
    "- [CS231 python tutorial 한글번역](http://aikorea.org/cs231n/python-numpy-tutorial/)\n",
    "- \n",
    "[Scipy-lectures](https://scipy-lectures.org/)\n",
    "    - [Numpy](https://scipy-lectures.org/intro/numpy/index.html)\n",
    "    - [Operations](https://scipy-lectures.org/intro/numpy/operations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "torch.Size([3])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# np.array (기본 단위 개체) -> torch.tensor(torch에서 기본 단위 개체 / vector, 다차원)\n",
    "\n",
    "b = torch.tensor([1,2,3])\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "torch.Size([3])\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# numpy -> tensor\n",
    "c = torch.from_numpy(a)\n",
    "print(c)\n",
    "print(c.shape)\n",
    "\n",
    "# tensor -> numpy\n",
    "d = c.numpy()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector의 표기 단위 차이\n",
    "\n",
    "* 수학에서 벡터의 기본 표기 단위\n",
    "    - Column (열) vector로 표기하는 것이 관습임.\n",
    "    - 예제\n",
    "    \\begin{align*}\n",
    "        x = \\begin{bmatrix}\n",
    "        x_1\\\\\n",
    "        x_2\\\\\n",
    "        x_3\n",
    "        \\end{bmatrix} \\in \\mathbb{R}^{3\\times 1}\n",
    "    \\end{align*}\n",
    "* pytorch에서 벡터의 기본 단위\n",
    "    - 다른 구조체와 메모리 구조상 Row (행) vector로 표기하는 것이 관습\n",
    "    - 예\n",
    "    \n",
    "    \n",
    "                                    `x = torch.tensor([1, 2, 3])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.tensor([1,3,4])\n",
    "print(d)\n",
    "d.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = d.reshape(1,-1).T\n",
    "d1\n",
    "\n",
    "# 2-d 이상 부터 transpose 명령어 실행 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python에서 Matrix 생성하기\n",
    "\n",
    "* 다음 $X\\in \\mathbb{R}^{2\\times 3}$ 행렬을 고려합시다:\n",
    "\\begin{align*}\n",
    "X = \\begin{bmatrix}\n",
    "5 & 6 & 8 \\\\\n",
    "6 & 7 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "* $X$ 행렬의 각 column (열)을 $x^{(i)}\\in \\mathbb{R}^2$이라고 하겠습니다. 즉, \n",
    "\\begin{align*}\n",
    "X = \\begin{bmatrix}\n",
    "x^{(1)} & x^{(2)} & x^{(3)}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "과 같이 표현 됩니다. 더 자세하게 한번더 설명하자면\n",
    "\\begin{align*}\n",
    "x^{(1)} = \\begin{bmatrix}\n",
    "5\\\\\n",
    "6\n",
    "\\end{bmatrix}, \\quad\n",
    "x^{(2)} = \\begin{bmatrix}\n",
    "6\\\\\n",
    "7\n",
    "\\end{bmatrix}, \\quad\n",
    "x^{(3)} = \\begin{bmatrix}\n",
    "8\\\\\n",
    "4\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* list에서 생성\n",
    "- indexing, slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 8],\n",
       "        [6, 7, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[5,6,8],[6,7,4]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 7])\n",
      "tensor([[6],\n",
      "        [7]])\n"
     ]
    }
   ],
   "source": [
    "print(X[:,1])    # column을 슬라이싱을 할 경우 squeeze한 형태인 row로 돌려줌 (원래의 모양을 유지하기 위해 reshape명령어 시용)\n",
    "print(X[:,1].reshape(-1,1))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tensor Attributes\n",
    "- `ndim`\n",
    "- `shape`\n",
    "- `dtype`\n",
    "- `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12,  3,  4]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[12,3,4]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype\n",
    "# torch의 자제적인 데이터 타입 존재(ex> dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device\n",
    "# tensor는 gpu에 올리는 것이 가능하기 때문에 현재 tensor가 어떤 디바이스에 올라가있는지 확인하는 명령어 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (중요) Python에서의 Vector \n",
    "\n",
    "* 1-D vector\n",
    "    - row vector만 표현 가능\n",
    "* 2-D vector\n",
    "    - row, column vector 모두 표현 가능\n",
    "* 어떤 방식을 사용해야하는가?\n",
    "* vector 또는 행렬에 적용하는 함수에 return 방식을 알고 있어야함!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (수학) 차원 확인 명령어\n",
    "- $X\\in\\mathbb{R}^{3\\times 1}$\n",
    "- `X.shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1],[2],[3]]).reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix 연산자 I\n",
    "- Transpose (전치) $X^T$\n",
    "    - `x.T`\n",
    "- `reshape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1., 2., 3.],\n",
    "       [4., 5., 6.]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.reshape(6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = X.reshape(6,1)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "# reshape이나 T 명령어는 원래의 tensor를 변형시키지 않는다(복사해서 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector transpose 주의점\n",
    "- (중요) transpose 연산자는 1D array는 변환하지 못한다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 다음 두개의 $x^{(i)}\\in\\mathbb{R}^3$ vector를 고려합시다:\n",
    "\\begin{align*}\n",
    "x^{(1)} = \\begin{bmatrix}\n",
    "5\\\\\n",
    "6\\\\\n",
    "8\n",
    "\\end{bmatrix}, \\quad\n",
    "x^{(2)} = \\begin{bmatrix}\n",
    "6\\\\\n",
    "7\\\\\n",
    "5\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "* $X$ 행렬의 각 row (행)을 $(x^{(i)})^T\\in \\mathbb{R}^{1\\times 3}$이라고 하겠습니다. 즉, \n",
    "\\begin{align*}\n",
    "X = \\begin{bmatrix}\n",
    "(x^{(1)})^T \\\\\n",
    "(x^{(2)})^T \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "과 같이 표현 됩니다. \n",
    "* 즉 $X\\in \\mathbb{R}^{2\\times 3}$ 는 다음과 같죠:\n",
    "\\begin{align*}\n",
    "X = \\begin{bmatrix}\n",
    "5 & 6 & 8 \\\\\n",
    "6 & 7 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1= tensor([[5],\n",
      "        [6],\n",
      "        [7]])\n",
      "x2= tensor([[6],\n",
      "        [7],\n",
      "        [5]])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([[5], [6], [7]])\n",
    "x2 = torch.tensor([[6], [7], [5]])\n",
    "print('x1=', x1)\n",
    "print('x2=', x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1T= tensor([[5, 6, 7]])\n",
      "x2T= tensor([[6, 7, 5]])\n"
     ]
    }
   ],
   "source": [
    "x1T = x1.T\n",
    "x2T = x2.T\n",
    "print('x1T=', x1T)\n",
    "print('x2T=', x2T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 7]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1TT = x1.reshape(1,3)\n",
    "x1TT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `vstack` (vertical (수직) stack (쌓다))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 7],\n",
       "        [6, 7, 5]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.vstack([x1.T, x2.T])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hstack` (horizontal (수평) stack (쌓다))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6, 7, 6, 7, 5]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhstack = torch.hstack([x1T, x2T])\n",
    "Xhstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6],\n",
       "        [6, 7],\n",
       "        [7, 5]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhstack2 = torch.hstack([x1, x2])\n",
    "Xhstack2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sequential Generation\n",
    "     - `ones`\n",
    "     - `zeros`\n",
    "     - `arange`\n",
    "     - `linspace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zvec = torch.zeros((1,3))\n",
    "zvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(5)\n",
      "tensor(6)\n",
      "tensor(7)\n",
      "tensor(8)\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "for i in torch.arange(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.4444, 0.8889, 1.3333, 1.7778, 2.2222, 2.6667, 3.1111, 3.5556,\n",
       "        4.0000])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Generation\n",
    "- `torch.rand`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6224, -0.0924,  0.8918,  0.0648, -0.2058,  0.3350,  0.8571, -0.6596,\n",
       "         -0.8924, -0.3227]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 2*torch.rand(1,10)-1\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gaussian (Normal) random generation\n",
    "    - pdf\n",
    "\\begin{align*}\n",
    "p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "\\end{align*}\n",
    "\n",
    "    - 정규분포 mean=0, variance = 1 생성 명령어\n",
    "`torch.randn` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0034,  1.6381,  2.3205,  ..., -1.8374, -0.9544, -1.5040],\n",
       "        [ 3.6394,  0.4175, -1.4507,  ...,  0.9502, -0.0170,  1.8947],\n",
       "        [ 4.8396,  4.7742,  1.1392,  ...,  1.9357,  5.1077,  0.7750],\n",
       "        ...,\n",
       "        [ 3.3821,  2.5469,  0.9295,  ..., -0.2775,  1.8022,  3.2595],\n",
       "        [ 1.4554,  3.1803,  0.4230,  ...,  6.0399,  0.7703,  3.9454],\n",
       "        [ 0.0182,  2.0036, -0.5207,  ..., -0.9682,  0.8140, -0.0987]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.sqrt(3)*torch.randn(30,40)+2\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0397)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(e)\n",
    "# 행렬 전체의 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2087)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(e)\n",
    "# 분산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7321])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.tensor([3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 차원축소\n",
    "* `squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.tensor([[[1,2,3,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matrix multiplication\n",
    "    - `matmul`\n",
    "    - Generate $A\\in\\mathbb{R}^{3\\times 2}$, $a^{(i)}\\in\\mathbb{R}^{3}$\n",
    "        \\begin{align*}\n",
    "            A = \\begin{bmatrix}\n",
    "                a^{(1)} & a^{(2)} & a^{(3)}  \n",
    "            \\end{bmatrix}\n",
    "        \\end{align*}\n",
    "        - Example, \n",
    "            \\begin{align*}\n",
    "            a^{(1)} = \\begin{bmatrix}\n",
    "                3 \\\\\n",
    "                4 \\\\\n",
    "                5 \\\\\n",
    "            \\end{bmatrix}\n",
    "        \\end{align*}\n",
    "    - Generate $B\\in\\mathbb{R}^{3\\times 4}$\n",
    "        \\begin{align*}\n",
    "            B = \\begin{bmatrix}\n",
    "                b^{(1)} & b^{(2)} & b^{(3)}  & b^{(4)}  \n",
    "            \\end{bmatrix}\n",
    "        \\end{align*}\n",
    "    - $(a^{(1)})^T \\cdot b^{(2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(0,6).reshape(3,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5857, -1.4199],\n",
       "        [-3.7232, -0.4598],\n",
       "        [-1.1887, -0.2281]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.randn(3,2)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5857, -0.4199],\n",
       "        [-1.7232,  2.5402],\n",
       "        [ 2.8113,  4.7719]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2],\n",
       "        [4]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = A[:, 0].reshape(3,1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5857, -1.4199],\n",
       "        [-3.7232, -0.4598],\n",
       "        [-1.1887, -0.2281]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4199],\n",
       "        [-0.4598],\n",
       "        [-0.2281]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = B[:, 1].reshape(-1,1)\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2464\\3861091728.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# torch 는 matmul 명령어를 사용할 때 casting 연산을 자동으로 적용하지 않음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
     ]
    }
   ],
   "source": [
    "torch.matmul(a1.T, b2)\n",
    "# torch 는 matmul 명령어를 사용할 때 casting 연산을 자동으로 적용하지 않음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1f = a1.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8317]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a1f.T, b2)\n",
    "# type 명령어도 원래의 행렬을 직접 변환하지 않기 때문에 다른 변수에 저장하여 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matrix operations\n",
    "    - sum(axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0664, -0.6715,  1.8510],\n",
       "        [-0.8034, -0.6647, -0.5162],\n",
       "        [-0.0614, -0.1603,  0.0900]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn(3,3)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3706, -0.1881, -0.3587],\n",
       "        [-0.6214, -0.1075,  1.5758],\n",
       "        [ 0.7822, -1.2095, -0.2419]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.randn(3,3)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = C[0,:]\n",
    "d1 = D[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2.])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = 2*torch.ones(4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6., 8.])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*b\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.reshape(-1,1).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a.type(torch.float32), b.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  4,  5,  6],\n",
       "        [ 7,  8,  9, 10]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(3,11, 1).reshape(2,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18],\n",
       "        [34]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asr = torch.sum(A, axis = 1).reshape(-1,1)\n",
    "asr\n",
    "# sum 함수도 size가 1이면 squeeze해서 출력(column을 유지하려면 reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 12, 14, 16]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc = torch.sum(A, axis = 0).reshape(1,-1)\n",
    "asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asum = torch.sum(A).reshape(-1,1)\n",
    "asum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 6., 7., 8.]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amc = torch.mean(A.type(torch.float32), axis = 0).reshape(1,-1)\n",
    "amc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000],\n",
       "        [8.5000]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amr = torch.mean(A.type(torch.float32), axis = 1).reshape(-1,1)\n",
    "amr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.5000]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am = torch.mean(A.type(torch.float32)).reshape(-1,1)\n",
    "am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 360.],\n",
       "        [5040.]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr = torch.prod(A.type(torch.float32), axis = 1).reshape(-1,1)\n",
    "apr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21., 32., 45., 60.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apc = torch.prod(A.type(torch.float32), axis = 0).reshape(1,-1)\n",
    "apc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1814400.]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap = torch.prod(A.type(torch.float32)).reshape(1,-1)\n",
    "ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Broadcasting\n",
    "\n",
    "![This is the caption\\label{mylabel}](https://scipy-lectures.org/_images/numpy_broadcasting.png)\n",
    "https://scipy-lectures.org/_images/numpy_broadcasting.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8078,  0.5979,  1.1191],\n",
       "        [ 1.7888, -0.5271, -1.1118],\n",
       "        [-1.0435,  0.0948,  0.5919],\n",
       "        [ 1.4369, -0.3106,  0.6704]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(4,3)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B= torch.ones((4,1))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8078,  1.5979,  2.1191],\n",
       "        [ 2.7888,  0.4729, -0.1118],\n",
       "        [-0.0435,  1.0948,  1.5919],\n",
       "        [ 2.4369,  0.6894,  1.6704]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
