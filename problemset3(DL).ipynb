{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))   # 60000개의 샘플 중에서 1000개씩을 랜덤하게 뽑음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape   #해당 이미지가 흑백이므로 검정색을 나타내를 채널 한 개만 존재, 각 이미지는 28x28 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1330)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.13), (0.3)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsample = images.reshape(images.shape[0], -1)  # batch size = 64로 고정, 28x28 픽셀을 row vector로 변환\n",
    "                                                # row1 = sample1, 각 샘플 feature = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Constructing the network model\n",
    "\n",
    "`FNC` class를 정의하고 `model`을 생성하세요:\n",
    "\n",
    "- input layer\n",
    "  - number of input features를 hidden unit 128개로 선형변환 및 ReLU activation function\n",
    "- Hidden layer\n",
    "  - 128 hidden unit을 64개 hidden unit으로 선형변환 및 ReLU\n",
    "- Output layer\n",
    "  - 64개 hidden unit을 10개 class로 분류하기 위한 output layer\n",
    "  - 최종 layer의 activation은 없음 (linear layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    # 답작성\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.seq = nn.Sequential(nn.Linear(Xsample.shape[1], 128),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(64, 10))\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions in PyTorch\n",
    "\n",
    "* 다음 과정으로, Pytorch에서 loss를 어떻게 연산하는지 배워보죠\n",
    "* `nn` module에서 다양한 loss function을 제공하는데, 예를 들면 `nn.CrossEntropyLoss`와 같은 함수가 있습니다\n",
    "    * 보통 관습적으로 loss function은 `critertion`이라는 변수로 받습니다 (`loss_function`등도 당연히 사용 가능합니다)\n",
    "* 지난 시간에 MNIST 문제는 확률 분포를 output으로 받는 것이 필요하다고 (또는 자연스러운 선택 임을) 학습했습니다 \n",
    "* 이런 확률 분포를 output으로 받는 경우 대응되는 좋은 loss function이 cross entropy입니다 (이론 강의에서 cross entropy가 무엇을 의미하는지 설명한 부분을 복습 해보세요)\n",
    "\n",
    "* Cross entropy의 정의는 \n",
    "\\begin{align*}\n",
    " J(\\theta) &=-\\frac{1}{m}\\sum_{i=1}^m P(y^{(i)}|x^{(i)})\\log(Q(y^{(i)}|x^{(i)}))\n",
    "\\end{align*}\n",
    "* 위 식은 두 확률 분포의 \"거리\"를 표현하는 식이라고 배웠습니다\n",
    "* 위에서 $P(y|x)$는 $y$의 label을 one hot coding 한 vector이고 $Q(y|x)$는 softmax를 취한 network output입니다\n",
    "* One hot coding은 label이 1이면 첫번째 자리만 '1'이고 나머지는 영인 벡터, label이 $k$이면 $k$ 번째 자리만 '1'이고 나머지는 0인 벡터입니다\n",
    "\n",
    "* 예를들어서 label이 2에 대한 one hot encoding\n",
    "\\begin{align*}\n",
    "y_\\textrm{one_hot}(2) &= \\begin{array}{cccccc}\n",
    "[0 & 0 & 1 & \\cdots & 0]\n",
    "\\end{array}\n",
    "\\end{align*}\n",
    "\n",
    "* 위 cross entropy 식에 대응 하는 방식은, label이 2라고 가정했을 때 분포는:\n",
    "\\begin{align*}\n",
    "P(y|x) = y_\\textrm{one_hot}(2), \\quad P(2|x) = (y_\\textrm{one_hot}(2))_2\n",
    "\\end{align*}\n",
    "\n",
    "* 또한, neural network의 마지막 linear layer의 output 값이 $z$라고 할때,\n",
    "\\begin{align*}\n",
    "Q(y=2|x) = \\sigma(z_2) = \\cfrac{\\exp(z_2)}{\\sum_k^K{\\exp(z_k)}}\n",
    "\\end{align*}\n",
    "\n",
    "![Classnote](https://drive.google.com/uc?export=download&id=17hcl4RJne65Vd17gKM8XKUTjYlqyFIY5)\n",
    "\n",
    "* pytorch에서 이를 수행하기 위해서 criterion을 `nn.CrossEntropyLoss`로 생성하고, network의 예측 값과, 실제 label 값을 입력으로 loss를 계산합니다\n",
    "  * 본 과정은 차근차근 설명하겠습니다\n",
    "* 그 전에 Pytorch에서 cross entropy 함수를 어떻게 적용하는지 먼저 이해할 필요가 있습니다 (중요합니다!!!)\n",
    "  * [Pytorch.org `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)를 살펴보면\n",
    "\n",
    "> This criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    ">\n",
    "> The input is expected to contain scores for each class.\n",
    "\n",
    "* `nn.CrossEntropyLoss`는 `nn.LogSoftmax()`와 `nn.NLLLoss()` 하나의 class에서 수행한다고 되어 있습니다. \n",
    "* 두번째 줄에서 NLLLoss 는 negative log likelihood loss 입니다 \n",
    "\n",
    "* 이게 의미하는 바가 무엇이냐면, network의 output을 softmax function을 적용하여 출력하지 말고, softmax는 loss function에서 계산한다는 뜻입니다\n",
    "* 이렇게 구현한 이유는, 확률값이 작을 수 있어서 computation precision error를 방지하기 위해서 그냥 raw output 값을 받고, loss function에서 log(prob) 형태로 연산하도록 모듈을 구성하였습니다\n",
    "\n",
    "* 아래 코드를 보면 조금 더 이해가 될 것이라고 생각합니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2848, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logits = model(images)   # 64개의 logit 존재; row vector의 형태\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Implement softmax\n",
    "\n",
    "다음 `softmax` 함수를 만드세요\n",
    "\n",
    "- `softmax(x)`\n",
    "- `input`: (batchsize, num_class)의 최종 linear layer output\n",
    "- `output`: `softmax` 취한 output이 (batchsize, softmaxoutput) 차원으로 정렬\n",
    "\n",
    "- 유용할 수 있는 함수:\n",
    "    - `torch.sum`\n",
    "    - `torch.exp`\n",
    "    - broadcasting 사용 (reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답작성\n",
    "def softmax(x):\n",
    "    softmax = torch.exp(x)/(torch.sum(torch.exp(x), axis = 1).reshape(-1,1))\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Finding the Highest probability index\n",
    "\n",
    "Sample별 예측 확률값을 통하여 가장 높은 확률 값 예측 받는 함수를 작성하세요.\n",
    "\n",
    "`get_pred(ps)`\n",
    "- `input`: sample 별 확률값을 (batchsize, class probabilities) 로 받음\n",
    "- `output`: sample 별로 가장 높은 확률값의 index를 return\n",
    "\n",
    "- 유용할 수 있는 함수\n",
    "  - `torch.argmax`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(ps):\n",
    "    # 답작성\n",
    "    return torch.argmax(ps, axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[ 0.0008,  0.0008,  0.0008,  ...,  0.0008,  0.0008,  0.0008],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        [-0.0005, -0.0005, -0.0005,  ..., -0.0005, -0.0005, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Before backward pass: \\n', model.seq[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model.seq[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network!\n",
    "\n",
    "\n",
    "* 자, 그럼 network parameter에 대한 loss function의 gradient를 구했으니, 이제 최적화를 할 수 있습니다\n",
    "* 최적화 기법은 SGD 이외에도 많으며 (SGD의 변형들임) [`optim` package](https://pytorch.org/docs/stable/optim.html)에서 찾아서 사용할 수 있습니다\n",
    "* 예를 들어서 SGD는 `optim.SGD`를 통해서 불러올 수 있습니다\n",
    "* 아래 예를 보죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model.parameters()는 우리 network의 모든 training parameter이며, lr는 learning rate 입니다\n",
    "* 자, 이제 traning에 필요한 모든 부분이 준비되었습니다\n",
    "* 전체 데이터에 대한 training은 숙제로 하고, 한 batch만 수행하는 과정을 살펴보죠\n",
    "* Pytorch에서 training의 전체 흐름은 다음과 같습니다:\n",
    "\n",
    "1. Network에서 forward pass\n",
    "2. Foward pass를 통해서 얻은 output을 활용하여 loss를 구한다\n",
    "3. Gradient를 구하기 위해서 `loss.backward()`를 실행한다\n",
    "4. Optimizer에서 weight를 한번 update 한다 (SGD의 경우 gradient에 대해서 한번 update)\n",
    "\n",
    "**[중요]**\n",
    "* 한가지 주의할 점은, 한 Parameter들에 대해서 gradient를 여러개 구해야하는 경우, (예, batch 처리) gradient 값들은 계속 추가적으로 저장됩니다\n",
    "* 한번 parameter update가 끝났으면, gradient 값을 초기화해야, 새로운 batch에 대한 새 gradient 값을 계산 합니다\n",
    "* 이를 위해서 batch 시작시에 `optimizer.zero_grad()`를 실행해줘야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0221, -0.0289, -0.0343,  ..., -0.0286,  0.0336, -0.0123],\n",
      "        [-0.0037, -0.0352,  0.0141,  ...,  0.0320,  0.0341,  0.0178],\n",
      "        [-0.0315, -0.0329,  0.0203,  ...,  0.0069, -0.0040, -0.0269],\n",
      "        ...,\n",
      "        [ 0.0216,  0.0038, -0.0264,  ...,  0.0053, -0.0162,  0.0270],\n",
      "        [-0.0319, -0.0066, -0.0260,  ..., -0.0053, -0.0260,  0.0333],\n",
      "        [-0.0068, -0.0254, -0.0292,  ..., -0.0084,  0.0345,  0.0339]],\n",
      "       requires_grad=True)\n",
      "Gradient - Parameter containing:\n",
      "tensor([[ 0.0221, -0.0290, -0.0344,  ..., -0.0286,  0.0336, -0.0123],\n",
      "        [-0.0035, -0.0350,  0.0143,  ...,  0.0323,  0.0344,  0.0180],\n",
      "        [-0.0316, -0.0329,  0.0202,  ...,  0.0068, -0.0040, -0.0270],\n",
      "        ...,\n",
      "        [ 0.0217,  0.0039, -0.0263,  ...,  0.0055, -0.0161,  0.0272],\n",
      "        [-0.0320, -0.0066, -0.0260,  ..., -0.0054, -0.0261,  0.0332],\n",
      "        [-0.0068, -0.0254, -0.0292,  ..., -0.0084,  0.0346,  0.0340]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model.seq[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "print('Gradient -', model.seq[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Starting epoch: 0 --------\n",
      "Training loss: 0.767835170681924\n",
      "Training acc: 0.8074526786804199\n",
      "------ Starting epoch: 1 --------\n",
      "Training loss: 0.3102142651881109\n",
      "Training acc: 0.9103644490242004\n",
      "------ Starting epoch: 2 --------\n",
      "Training loss: 0.25643669805531183\n",
      "Training acc: 0.9252398610115051\n",
      "------ Starting epoch: 3 --------\n",
      "Training loss: 0.22010646869680647\n",
      "Training acc: 0.9362506866455078\n",
      "------ Starting epoch: 4 --------\n",
      "Training loss: 0.19162460144505952\n",
      "Training acc: 0.9450626373291016\n",
      "------ Starting epoch: 5 --------\n",
      "Training loss: 0.16890465341476615\n",
      "Training acc: 0.9512426853179932\n",
      "------ Starting epoch: 6 --------\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 100\n",
    "loss_epoch = []\n",
    "acc_epoch = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(f\"------ Starting epoch: {e} --------\")\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "    \n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        ps = softmax(logits)\n",
    "        pred = get_pred(ps)\n",
    "        running_acc += torch.sum(pred==labels)/labels.shape[0] \n",
    "        \n",
    "               \n",
    "    acc_epoch.append(running_acc/len(trainloader))    \n",
    "    loss_epoch.append(running_loss/len(trainloader))\n",
    "    print(f\"Training loss: {loss_epoch[e]}\")\n",
    "    print(f\"Training acc: {acc_epoch[e]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), loss_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), acc_epoch)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = softmax(logps)\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
