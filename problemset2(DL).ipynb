{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36a2146",
   "metadata": {},
   "source": [
    "이름: \n",
    "\n",
    "학번:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069c04dd",
   "metadata": {},
   "source": [
    "# Neural networks with PyTorch\n",
    "\n",
    "Pytorch의 `nn.module`을 활용하여 만드는 유용한 방법을 학습합니다.\n",
    "\n",
    "<div style=\"text-align:center\"><img src='https://drive.google.com/uc?export=download&id=1J2SeiPpVJs1-ML2BdLrcxkGGmHpRxIVE' width=\"250\" height=\"200\"> \n",
    "\n",
    "### Lego block coding! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd06918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19229d25110>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605a354",
   "metadata": {},
   "source": [
    "`nn.Linear`: $Z^{[\\ell]} = A^{[\\ell-1]}W^T+b$\n",
    "연산.\n",
    "\n",
    "해당 layer의 \n",
    "\n",
    "- 입력 차원 `n_input=30`\n",
    "- 출력 차원 `n_output=60`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe1c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of nn.linear\n",
    "linear_layer1 = nn.Linear(30, 60)\n",
    "# -> output을 60으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4a14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 60])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn(60, 30)\n",
    "linear_layer1(A).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08df3e97-f02f-46a0-869e-268b686b990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = torch.randn(20,30)\n",
    "# linear_layer2 = nn.Linear(30,3)\n",
    "# linear_layer2(B).shape\n",
    "# linear_layer2.weight.data  # tensor의 형태로 돌려줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcbcbf",
   "metadata": {},
   "source": [
    "How to get the weights and bias of each `nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e636fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of weights\n",
    "linear_layer1.weight.data = torch.ones_like(linear_layer1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214864da-24f2-454f-8f90-3db57cfefa91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer1.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a96b2d",
   "metadata": {},
   "source": [
    "### NN example\n",
    "\n",
    "- input units: 20\n",
    "- hidden layer: 30, 40\n",
    "- output units: 3\n",
    "- activation function: ReLU\n",
    "- output layer: No activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c09e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN construction\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()   # FCN class의 __init__ 함수 안에서 super class인 nn.Module의 __init__ 함수를 부른다. \n",
    "        \n",
    "        self.lin1 = nn.Linear(20, 30)\n",
    "        self.lin2 = nn.Linear(30, 40)\n",
    "        self.lin3 = nn.Linear(40, 3)  \n",
    "        self.relu = nn.ReLU(True)   # 메모리 절약\n",
    "        \n",
    "    def forward(self, x):   # 함수 이름은 forward로 고정\n",
    "        x = self.lin1(x)   \n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)   # 위에서 정의된 lin연산과 relu연산을 번갈아가며 하기 위해서 self 변수를 받음\n",
    "        x = self.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88009d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.randn(60, 20)   # 60x20 Xtrain 행렬 정의\n",
    "\n",
    "model = FCN()   # model이라는 이름으로 FCN class 생성\n",
    "\n",
    "#model(Xtrain)   # 위의 셀에서 함수 이름을 forward로 정의하면 model.forward(Xtrain)와 model(Xtrain)이 같은 결과값을 돌려줌(연속적인 선형결합)\n",
    "                # 20,30 -> 30,40 -> 40,3 => 20x3 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f646b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN(\n",
       "  (lin1): Linear(in_features=20, out_features=30, bias=True)\n",
       "  (lin2): Linear(in_features=30, out_features=40, bias=True)\n",
       "  (lin3): Linear(in_features=40, out_features=3, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "# __init__ 정의된 변수와 lin 객체들을 돌려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a24fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of parameters() in models\n",
    "# param_iterator = model.parameters()\n",
    "\n",
    "# for param in param_iterator:\n",
    "#     print(param)\n",
    "\n",
    "# for문 없이는 iterator 객체 내부의 값을 확인할 수 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929f4cb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19784\\2488942605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# nn.Sequential() example\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mFCN_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# nn.Sequential() example\n",
    "\n",
    "class FCN_seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(20, 30),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(30, 40),\n",
    "                      nn.ReLU(True),\n",
    "                      nn.Linear(40, 3)   # nn.Sequential함수가 contents들을 순차적으로 결합\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)                # 위의 예제에서와 같이 함수이름을 forward로 하면 사용이 용이\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653f0bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq = FCN_seq()   # 생성\n",
    "Xtrain.shape \n",
    "model_seq\n",
    "\n",
    "# model_seq(Xtrain) -> class 내부에 forward 함수를 정의하지 않으면 불가능\n",
    "# model_seq.fc(Xtrain) -> nn.Sequential에 forward 내포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0db292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=30, bias=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq.fc[0]\n",
    "\n",
    "# nn.Sequential 인덱싱 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a16dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_seq_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        \n",
    "        temp = self.fcn_block(20, 30)+self.fcn_block(30, 40)+[nn.Linear(40,1)]  # 아래서 정의된 함수 사용, 마지막 layer는 relu 적용x -> 바로 list로 return\n",
    "        self.fc = nn.Sequential(*temp)   # temp의 data만 추출\n",
    "        \n",
    "        \n",
    "    def fcn_block(self, in_dim, out_dim):   # input과 output을 변수로 전달\n",
    "        return [nn.Linear(in_dim, out_dim),   # nn.Linear(in, out)적용한 결과와 relu 결과를\n",
    "                             nn.ReLU(True)]   # list 형태로 return\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac30117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_seq_v2(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_seq_v2 = FCN_seq_v2()\n",
    "model_seq_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "514cccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_final(nn.Module):\n",
    "    def __init__(self, in_dim, hlayer, out_dim):\n",
    "        super().__init__()\n",
    "                                                     # in=20 hidden=[30,40,50,60] out=70\n",
    "        l_list = self.fcn_block(in_dim, hlayer[0])   # [20,30]\n",
    "        \n",
    "        for l1, l2 in zip(hlayer[:-1], hlayer[1:]):   # [30,40,50,60] -> [30,40,50],[40,50,60] 두 개의 list들을 같은 인덱스끼리 짝지어 in, out에 입력\n",
    "            l_list = l_list + self.fcn_block(l1, l2)   # 선형결합한 각 결과들을 list에 차례로 추가\n",
    "        \n",
    "        l_list = l_list + [nn.Linear(hlayer[-1], out_dim)]   #[60,70]\n",
    "        \n",
    "        self.fc = nn.Sequential(*l_list)   # l_list의 내용물을 Sequential함수로 저장\n",
    "        \n",
    "        \n",
    "    def fcn_block(self, in_dim, out_dim):\n",
    "        return [nn.Linear(in_dim, out_dim),\n",
    "                             nn.ReLU(True)]   # return list\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05a543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hlayer = [30, 40]\n",
    "in_dim = 20\n",
    "out_dim= 3\n",
    "\n",
    "myfcn_final = FCN_final(in_dim, hlayer, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d545559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_final(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=30, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=40, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfcn_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d419c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered dict example\n",
    "# nn.Sequential() example\n",
    "\n",
    "class FCN_seq_ordered_dic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([('lin1', nn.Linear(20, 30)),\n",
    "                      ('relu1', nn.ReLU(True)),\n",
    "                      ('lin2', nn.Linear(30, 40)),\n",
    "                      ('relu2',nn.ReLU(True)),\n",
    "                      ('lin3', nn.Linear(40, 3))\n",
    "                                            ])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "# self.lin1 = nn.Linear(20, 30)\n",
    "# self.lin2 = nn.Linear(30, 40)\n",
    "# self.lin3 = nn.Linear(40, 3)\n",
    "# self.relu = nn.ReLU(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a876e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModuleList(), ModuleDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb4c2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict() example\n",
    "#model.state_dict()\n",
    "# -> OrderDict 타입으로 이름과 내용을 돌려줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c586f6",
   "metadata": {},
   "source": [
    "# Problem Setup\n",
    "\n",
    "<div style=\"text-align:center\"> <img src='https://drive.google.com/uc?export=download&id=1FRhniwGeeutBSJQRdW6GzshMfDrPz7oJ' width=\"250\" height=\"200\"> </div>\n",
    "    \n",
    "Build a Fully connected neural network with\n",
    "\n",
    "- 3 layers\n",
    "- 마지막 layer의 unit 수는 `1` \n",
    "  - 마지막 layer의 activation은 없음 (linear layer)\n",
    "- Data feature 수는 `100`\n",
    "\n",
    "- input unit 수는 data 크기를 보고 맞추세요\n",
    "- hidden layer의 unit 수는 `[80, 50]`\n",
    "  - hidden layer의 activation 함수는 ReLU\n",
    "\n",
    "- model class 명 `myFCN`\n",
    "  - instance 명 `my_model` 생성\n",
    "  - `my_model` 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8150a-5d25-40fe-951a-416a5f022112",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "problem setup에서 구성한 neural network을 `nn.Sequential`을 활용하여 생성하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dabeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사용할 data \n",
    "batch_size = 30\n",
    "num_feature = 100\n",
    "\n",
    "X_train = torch.randn(batch_size, num_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc5c673c-068b-4201-8900-3669a84d420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3265cdca-284b-4378-834e-ef6adb526b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 1 코딩 (매 줄마다 주석 필수 )\n",
    "\n",
    "class myFCN(nn.Module):   # class myFCN 정의 \n",
    "    def __init__(self, in_dim, h_layer, out_dim):   # in-out unit 과 hidden layer unit을 받습니다.\n",
    "        super().__init__()                          # myFCN class의 __init__ 함수 안에서 super class인 nn.Module의 __init__ 함수를 부릅니다. \n",
    "        \n",
    "        l_list = self.fcn_block(in_dim, h_layer[0])   # in_dim은 hidden layer unit과 다른 변수로 받기 때문에 첫번째 layer는 fcn_block 함수로 먼저 연산합니다.\n",
    "        \n",
    "        for l1, l2 in zip(h_layer[:-1], h_layer[1:]): # h_layer list 중 마지막 layer를 뺀 l1, 첫 번째 layer를 뺀 l2 두 개의 list에서 같은 인덱스끼리 짝지어서\n",
    "            l_list = l_list + self.fcn_block(l1, l2)  # fcn_block(in, out)에 입력하고 각 결과들을 list에 차례로 추가합니다.\n",
    "            \n",
    "        l_list = l_list + [nn.Linear(h_layer[-1], out_dim)]   # 마지막 layer는 ReLU를 적용하지 않기 때문에 바로 list로 저장합니다.\n",
    "        \n",
    "        self.fc = nn.Sequential(*l_list)   # l_list의 contents를 Sequential함수로 저장, nn.Sequential함수가 contents들을 순차적으로 결합 합니다.\n",
    "        \n",
    "        \n",
    "    def fcn_block(self, in_dim, out_dim):                    # in_dim 과 out_dim을 변수로 전달합니다.\n",
    "        return [nn.Linear(in_dim, out_dim), nn.ReLU(True)]   # 변수들의 선형결합 결과와 ReLU를 적용한 결과를 list 형태로 return 합니다.\n",
    "    \n",
    "    def forward(self, x):   \n",
    "        return self.fc(x)   # nn.Sequential을 이용하여 l_list의 data를 self.fc에 저장하고 forward 함수를 정의하여 self.fc를 return하면\n",
    "                            # instance를 생성했을 떄 사용이 편리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "846477b3-37df-43a8-874c-f6c903e797c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myFCN(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=80, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=80, out_features=50, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_layer = [80, 50]     # hidden layer unit \n",
    "in_dim = num_feature   # input은 feature 개수에 의해 결정됩니다.\n",
    "out_dim= 1             # output은 activation이 없고 unit이 1개 입니다.\n",
    "\n",
    "my_model = myFCN(in_dim, h_layer, out_dim)   # 이름이 my_model인 instance를 생성합니다.\n",
    "my_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a46397a2-bf43-43cd-9c2c-fb1143009f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc48cc",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "problem setup에서 구성한 neural network을 `OrderedDict`을 활용하여 생성하세요\n",
    "- 각 layer의 이름을 주고 생성하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50011c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0b7a32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myFCN_order(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([('lin1', nn.Linear(in_dim, h_layer[0])),\n",
    "                      ('relu1', nn.ReLU(True)),\n",
    "                      ('lin2', nn.Linear(h_layer[0], h_layer[1])),\n",
    "                      ('relu2',nn.ReLU(True)),\n",
    "                      ('lin3', nn.Linear(h_layer[1], out_dim))\n",
    "                                            ])\n",
    "        )\n",
    "                                                                 # python에 있는 OrderedDict 로 이름이나 숫자를 부여해주면\n",
    "                                                                    # 보다 쉬운 식별이 가능합니다.\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e3659cdb-bbb3-4857-89dc-d8c571140a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myFCN_order(\n",
       "  (fc): Sequential(\n",
       "    (lin1): Linear(in_features=100, out_features=80, bias=True)\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (lin2): Linear(in_features=80, out_features=50, bias=True)\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (lin3): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = myFCN_order()   # instance 생성\n",
    "my_model                   # myFCN_order class에서 설정한 이름으로 my_model의 정보를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b57113e3-a0b1-4976-8390-be05a39b555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=80, bias=True)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fc.lin1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
